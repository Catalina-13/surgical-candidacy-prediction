{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c3d39ba",
   "metadata": {},
   "source": [
    "# Confidence-Based Classification Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b5771f",
   "metadata": {},
   "source": [
    "This notebook implements a customized machine learning pipeline to predict a binary target using XGBoost with a custom loss function and a custom scoring metric. It includes:\n",
    "\n",
    "- Data loading and preprocessing\n",
    "- Definition of a shifted quadratic loss function tailored for the problem\n",
    "- A custom scoring function that prioritizes confident true negatives and true positives\n",
    "- A custom XGBoost wrapper to integrate the custom loss into training\n",
    "- Splitting of data into train, validation, and test sets\n",
    "- Hyperparameter tuning via GridSearchCV on the training+validation data\n",
    "- Model evaluation on the test set with multiple metrics:\n",
    "    - Accuracy, classification report, confusion matrix\n",
    "    - AUROC and AUPRC\n",
    "    - Precision-Recall curve analysis with threshold tuning\n",
    "    - Analysis of Positive Predictive Value (PPV) and Negative Predictive Value (NPV) across thresholds\n",
    "- Visualization of prediction performance and threshold effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0282bbff",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33695ce1-c7fb-4195-bdc4-a3fdac9bc3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, average_precision_score, precision_recall_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0497e47f-aeb8-462b-a778-027827177756",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb6695b-341b-484f-8842-95284eaf1c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('your_dataset.csv') # Replace 'your_dataset.csv' with your actual file path\n",
    "data = pd.DataFrame(data) # Optional if data is already a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa2361d",
   "metadata": {},
   "source": [
    "## 3. Custom Shifted Quadratic Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifted_quadratic_loss(preds, dtrain, m=2.0, v=0.3, b=0.1):\n",
    "    y = dtrain.get_label()\n",
    "    p = 1 / (1 + np.exp(-preds))  # Sigmoid\n",
    "    \n",
    "    # Shifted quadratic weight\n",
    "    weight = m * ((p - v) ** 2) + b\n",
    "    d_weight_dp = 2 * m * (p - v)\n",
    "    \n",
    "    grad = weight * (p - y)\n",
    "    hess = weight * p * (1 - p) + d_weight_dp * (p - y)\n",
    "    \n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05608c37",
   "metadata": {},
   "source": [
    "## 4. Custom Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feb3f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom Goal Function: prioritize confident true negatives and positives ---\n",
    "def compute_custom_goal(probas, y_actual):\n",
    "    confident_tn = (probas <= 0.05) & (y_actual == 0) # Confident True Negatives: at least 95% confidence level\n",
    "    confident_tp = (probas >= 0.80) & (y_actual == 1) # Confident True Positives: at least 80% confidence level\n",
    "    return np.sum(confident_tn | confident_tp)\n",
    "\n",
    "# --- Scoring Function for GridSearchCV ---\n",
    "def n95_minus_scorer(estimator, X_val, y_val):\n",
    "    probas = estimator.predict_proba(X_val)[:, 1]\n",
    "    return compute_custom_goal(probas, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf73339",
   "metadata": {},
   "source": [
    "## 5. Custom XGBoost Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fbdb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBCustomWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, m=2.0, v=0.3, b=0.1, learning_rate=0.1, max_depth=3,\n",
    "                 min_child_weight=1, subsample=1.0, colsample_bytree=1.0,\n",
    "                 scale_pos_weight=1.0, num_boost_round=100):\n",
    "        self.m = m\n",
    "        self.v = v\n",
    "        self.b = b\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_child_weight = min_child_weight\n",
    "        self.subsample = subsample\n",
    "        self.colsample_bytree = colsample_bytree\n",
    "        self.scale_pos_weight = scale_pos_weight\n",
    "        self.num_boost_round = num_boost_round\n",
    "        self.booster = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        dtrain = xgb.DMatrix(X, label=y)\n",
    "        self.booster = xgb.train(\n",
    "            {\n",
    "                'objective': 'binary:logistic',\n",
    "                'disable_default_eval_metric': 1,\n",
    "                'learning_rate': self.learning_rate,\n",
    "                'max_depth': self.max_depth,\n",
    "                'min_child_weight': self.min_child_weight,\n",
    "                'subsample': self.subsample,\n",
    "                'colsample_bytree': self.colsample_bytree,\n",
    "                'scale_pos_weight': self.scale_pos_weight,\n",
    "            },\n",
    "            dtrain,\n",
    "            num_boost_round=self.num_boost_round,\n",
    "            obj=lambda preds, dtrain: shifted_quadratic_loss(preds, dtrain, self.m, self.v, self.b)\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        dmatrix = xgb.DMatrix(X)\n",
    "        probas = self.booster.predict(dmatrix)\n",
    "        return np.vstack([1 - probas, probas]).T\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X)[:, 1] >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64f461",
   "metadata": {},
   "source": [
    "## 6. Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364dd681",
   "metadata": {},
   "source": [
    "- **Training set**: Used to fit the model and learn from the data. The model adjusts its parameters based on this data.\n",
    "- **Validation set**: Used during model development to tune hyperparameters and select the best model. It acts as an independent check to prevent overfitting on the training data.\n",
    "- **Test set**: Completely held out until the very end, used for the final unbiased evaluation of the modelâ€™s performance on unseen data.\n",
    "\n",
    "\n",
    "1. Split the data into train + validation (80%) and test (20%).\n",
    "2. Further split train + validation into training (60%) and validation (20%).\n",
    "3. Perform hyperparameter tuning (GridSearchCV) on the training set.\n",
    "4. Evaluate and select models based on performance on the validation set.\n",
    "5. After selecting the best model, test its final performance on the test set to get an unbiased estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada9cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Preprocessing ---\n",
    "X = data.drop('target_column', axis=1) # Replace 'target_column' with the name of your target variable\n",
    "y = data['target_column'] # Replace accordingly\n",
    "\n",
    "# First split: hold out test set (e.g., 20%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: split remaining data into train and validation (e.g., 25% of 80% = 20% of total)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcba0d6b",
   "metadata": {},
   "source": [
    "## 7. Pipeline and Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6dee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', XGBCustomWrapper())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'xgb__m': [5.0, 6.0, 4.0],\n",
    "    'xgb__v': [0.35, 0.1, 0.15],\n",
    "    'xgb__b': [0.05, 0.03],\n",
    "    'xgb__learning_rate': [0.05, 0.1],\n",
    "    'xgb__max_depth': [5, 10],\n",
    "    'xgb__min_child_weight': [1, 3],\n",
    "    'xgb__subsample': [0.8, 1.0],\n",
    "    'xgb__colsample_bytree': [0.8, 1.0],\n",
    "    'xgb__scale_pos_weight': [1, 2],\n",
    "    'xgb__num_boost_round': [100, 200, 300, 400]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e726426d",
   "metadata": {},
   "source": [
    "## 8. Grid Search for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9817fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=n95_minus_scorer,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit on training + validation set\n",
    "gscv.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531015e1",
   "metadata": {},
   "source": [
    "## 9. Model Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe28994",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters Found:\")\n",
    "print(gscv.best_params_)\n",
    "\n",
    "best_model = gscv.best_estimator_\n",
    "\n",
    "# Get predictions\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate on testing set\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Testing Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c5a8a7",
   "metadata": {},
   "source": [
    "## 10. Advanced Metrics and Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abacf045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities for the positive class\n",
    "test_probas = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 1. AUROC\n",
    "auroc = roc_auc_score(y_test, test_probas)\n",
    "print(f\"AUROC: {auroc:.4f}\")\n",
    "\n",
    "# 2. AUPRC\n",
    "auprc = average_precision_score(y_test, test_probas)\n",
    "print(f\"AUPRC: {auprc:.4f}\")\n",
    "\n",
    "# 3. Precision-Recall Curve for max PPV\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, test_probas)\n",
    "\n",
    "# Remove the last precision and recall point\n",
    "precision = precision[:-1]\n",
    "recall = recall[:-1]\n",
    "\n",
    "# Find threshold with maximum precision (PPV)\n",
    "max_ppv_idx = np.argmax(precision)\n",
    "max_ppv = precision[max_ppv_idx]\n",
    "ppv_threshold = thresholds[max_ppv_idx]\n",
    "\n",
    "# % of predictions made at or above this threshold\n",
    "high_conf_preds = test_probas >= ppv_threshold\n",
    "percent_classified_at_max_ppv = 100 * np.mean(high_conf_preds)\n",
    "\n",
    "print(f\"Maximum PPV: {max_ppv:.4f} at threshold {ppv_threshold:.4f}\")\n",
    "print(f\"Percentage of test observations classified at max PPV threshold: {percent_classified_at_max_ppv:.2f}%\")\n",
    "\n",
    "# 4. Compute NPV at various thresholds\n",
    "npv_thresholds = np.arange(0.05, 1.00, 0.05)\n",
    "npv_values = []\n",
    "percent_classified_at_npv = []\n",
    "\n",
    "for thresh in npv_thresholds:\n",
    "    preds = (test_probas < thresh).astype(int)  # Predict negative if below threshold\n",
    "    tn = np.sum((preds == 1) & (y_test == 0))\n",
    "    fn = np.sum((preds == 1) & (y_test == 1))\n",
    "    if (tn + fn) > 0:\n",
    "        npv = tn / (tn + fn)\n",
    "        pct = 100 * (tn + fn) / len(y_test)\n",
    "    else:\n",
    "        npv = 0\n",
    "        pct = 0\n",
    "    npv_values.append(npv)\n",
    "    percent_classified_at_npv.append(pct)\n",
    "\n",
    "# Find threshold with maximum NPV\n",
    "max_npv_idx = np.argmax(npv_values)\n",
    "max_npv = npv_values[max_npv_idx]\n",
    "npv_threshold = npv_thresholds[max_npv_idx]\n",
    "percent_classified_at_max_npv = percent_classified_at_npv[max_npv_idx]\n",
    "\n",
    "print(f\"Maximum NPV: {max_npv:.4f} at threshold {npv_threshold:.2f}\")\n",
    "print(f\"Percentage of test observations classified at max NPV threshold: {percent_classified_at_max_npv:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8ebdf9",
   "metadata": {},
   "source": [
    "## 11. Visualization - Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad265cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0.05, 1.0, 0.05)\n",
    "tp_perc, tn_perc, fp_perc, fn_perc = [], [], [], []\n",
    "ppv, npv = [], []\n",
    "perc_pred_1, perc_pred_0 = [], []\n",
    "\n",
    "total = len(y_test)\n",
    "probas_positive = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "for i in thresholds:\n",
    "    preds = (probas_positive >= i).astype(int)\n",
    "\n",
    "    TP = np.sum((preds == 1) & (y_test == 1))\n",
    "    TN = np.sum((preds == 0) & (y_test == 0))\n",
    "    FP = np.sum((preds == 1) & (y_test == 0))\n",
    "    FN = np.sum((preds == 0) & (y_test == 1))\n",
    "\n",
    "    tp_perc.append(TP / total * 100)\n",
    "    tn_perc.append(TN / total * 100)\n",
    "    fp_perc.append(FP / total * 100)\n",
    "    fn_perc.append(FN / total * 100)\n",
    "\n",
    "    ppv.append(TP / (TP + FP) if (TP + FP) > 0 else np.nan)\n",
    "    npv.append(TN / (TN + FN) if (TN + FN) > 0 else np.nan)\n",
    "\n",
    "    perc_pred_1.append((TP + FP) / total * 100)\n",
    "    perc_pred_0.append((TN + FN) / total * 100)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Threshold\": thresholds,\n",
    "    \"TP %\": tp_perc,\n",
    "    \"FP %\": fp_perc,\n",
    "    \"TN %\": tn_perc,\n",
    "    \"FN %\": fn_perc,\n",
    "    \"PPV (Precision)\": ppv,\n",
    "    \"NPV\": npv,\n",
    "    \"Predicted 1 %\": perc_pred_1,\n",
    "    \"Predicted 0 %\": perc_pred_0\n",
    "})\n",
    "\n",
    "# Stacked bar plot\n",
    "plt.figure(figsize=(12, 7))\n",
    "bar_tp = plt.bar(thresholds, tp_perc, width=0.03, label='True Positives')\n",
    "bar_fp = plt.bar(thresholds, fp_perc, width=0.03, bottom=np.array(tp_perc), label='False Positives')\n",
    "bar_tn = plt.bar(thresholds, tn_perc, width=0.03, bottom=np.array(tp_perc) + np.array(fp_perc), label='True Negatives')\n",
    "bar_fn = plt.bar(thresholds, fn_perc, width=0.03, bottom=np.array(tp_perc) + np.array(fp_perc) + np.array(tn_perc), label='False Negatives')\n",
    "\n",
    "# Annotate bars\n",
    "for bar, data, offset in zip([bar_tp, bar_fp, bar_tn, bar_fn], \n",
    "                             [tp_perc, fp_perc, tn_perc, fn_perc],\n",
    "                             [np.zeros(len(tp_perc)), \n",
    "                              np.array(tp_perc), \n",
    "                              np.array(tp_perc) + np.array(fp_perc), \n",
    "                              np.array(tp_perc) + np.array(fp_perc) + np.array(tn_perc)]):\n",
    "    for rect, perc, base in zip(bar, data, offset):\n",
    "        if perc > 0:\n",
    "            height = rect.get_height()\n",
    "            plt.text(rect.get_x() + rect.get_width() / 2, base + height / 2,\n",
    "                     f'{perc:.1f}%', ha='center', va='center', fontsize=9, color='black')\n",
    "\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.title('Threshold Analysis: TP, FP, TN, FN by Confidence Threshold')\n",
    "plt.legend()\n",
    "plt.xticks(thresholds, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fee6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_conf = []  # PPV\n",
    "neg_conf = []  # NPV\n",
    "frac_pos = []\n",
    "frac_neg = []\n",
    "\n",
    "\n",
    "for i in thresholds:\n",
    "    preds = (probas_positive >= i).astype(int)\n",
    "\n",
    "    TP = np.sum((preds == 1) & (y_test == 1))\n",
    "    TN = np.sum((preds == 0) & (y_test == 0))\n",
    "    FP = np.sum((preds == 1) & (y_test == 0))\n",
    "    FN = np.sum((preds == 0) & (y_test == 1))\n",
    "\n",
    "    ppv = TP / (TP + FP) if (TP + FP) > 0 else np.nan\n",
    "    npv = TN / (TN + FN) if (TN + FN) > 0 else np.nan\n",
    "\n",
    "    frac_pred_pos = np.mean(preds == 1)\n",
    "    frac_pred_neg = np.mean(preds == 0)\n",
    "\n",
    "    pos_conf.append(ppv)\n",
    "    neg_conf.append(npv)\n",
    "    frac_pos.append(frac_pred_pos)\n",
    "    frac_neg.append(frac_pred_neg)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "plt.plot(thresholds, pos_conf, marker='x', linestyle='-', color='blue', label='Positive Precision (PPV)')\n",
    "plt.plot(thresholds, neg_conf, marker='x', linestyle='-', color='green', label='Negative Precision (NPV)')\n",
    "plt.plot(thresholds, frac_pos, linestyle='--', marker='^', color='blue', label='Fraction Predicted Positive')\n",
    "plt.plot(thresholds, frac_neg, linestyle='--', marker='v', color='green', label='Fraction Predicted Negative')\n",
    "\n",
    "plt.axhline(0.80, color='black', linestyle='--')\n",
    "plt.axhline(0.90, color='black', linestyle='--')\n",
    "\n",
    "for i, t in enumerate(thresholds):\n",
    "    if not np.isnan(pos_conf[i]) and pos_conf[i] >= 0.80:\n",
    "        plt.annotate(f'{pos_conf[i]:.2f}', (t, pos_conf[i]), textcoords=\"offset points\", xytext=(0,10), ha='center', color='blue')\n",
    "    if not np.isnan(neg_conf[i]) and neg_conf[i] >= 0.80:\n",
    "        plt.annotate(f'{neg_conf[i]:.2f}', (t, neg_conf[i]), textcoords=\"offset points\", xytext=(0,-15), ha='center', color='green')\n",
    "\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Confidence vs Threshold (PPV, NPV)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(thresholds, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_conf = []  # PPV\n",
    "neg_conf = []  # NPV\n",
    "frac_pos = []\n",
    "frac_neg = []\n",
    "actual_pos_frac = []\n",
    "\n",
    "for i in thresholds:\n",
    "    preds = (probas_positive >= i).astype(int)\n",
    "\n",
    "    TP = np.sum((preds == 1) & (y_test == 1))\n",
    "    TN = np.sum((preds == 0) & (y_test == 0))\n",
    "    FP = np.sum((preds == 1) & (y_test == 0))\n",
    "    FN = np.sum((preds == 0) & (y_test == 1))\n",
    "\n",
    "    ppv = TP / (TP + FP) if (TP + FP) > 0 else np.nan\n",
    "    npv = TN / (TN + FN) if (TN + FN) > 0 else np.nan\n",
    "\n",
    "    frac_pred_pos = np.mean(preds == 1)\n",
    "    frac_pred_neg = np.mean(preds == 0)\n",
    "\n",
    "    pos_conf.append(ppv)\n",
    "    neg_conf.append(npv)\n",
    "    frac_pos.append(frac_pred_pos)\n",
    "    frac_neg.append(frac_pred_neg)\n",
    "    act_pos_frac = TP / np.sum(preds == 1) if np.sum(preds == 1) > 0 else np.nan\n",
    "    actual_pos_frac.append(act_pos_frac)\n",
    "\n",
    "# ------------------ POSITIVE METRICS PLOT ------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, pos_conf, marker='x', linestyle='-', color='blue', label='Positive Precision (PPV)')\n",
    "plt.plot(thresholds, frac_pos, linestyle='--', color='blue', label='Fraction Predicted Positive')\n",
    "plt.axhline(0.80, color='black', linestyle='--', label='Target Confidence: 0.80')\n",
    "\n",
    "for i, t in enumerate(thresholds):\n",
    "    if not np.isnan(pos_conf[i]) and pos_conf[i] >= 0.80:\n",
    "        plt.annotate(f'{pos_conf[i]:.2f}', (t, pos_conf[i]), textcoords=\"offset points\", xytext=(0,10), ha='center', color='blue')\n",
    "\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Positive Prediction Confidence vs Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(thresholds, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------ NEGATIVE METRICS PLOT ------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, neg_conf, marker='x', linestyle='-', color='green', label='Negative Precision (NPV)')\n",
    "plt.plot(thresholds, frac_neg, linestyle='--', color='green', label='Fraction Predicted Negative')\n",
    "plt.axhline(0.90, color='black', linestyle='--', label='Target Confidence: 0.90')\n",
    "\n",
    "for i, t in enumerate(thresholds):\n",
    "    if not np.isnan(neg_conf[i]) and neg_conf[i] >= 0.90:\n",
    "        plt.annotate(f'{neg_conf[i]:.2f}', (t, neg_conf[i]), textcoords=\"offset points\", xytext=(0,10), ha='center', color='green')\n",
    "\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Negative Prediction Confidence vs Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(thresholds, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d714b517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
